{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea05a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import data_preprocessing.data_preprocess as dp\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42cb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_vars = [\n",
    "    \"Military: Positive\",\n",
    "    \"European Community/Union: Positive\",\n",
    "    \"Freedom and Human Rights\",\n",
    "    \"Democracy\",\n",
    "    \"Political Corruption\",\n",
    "    \"Environmental Protection\",\n",
    "    \"Welfare State\",\n",
    "    \"Right-left position\",\n",
    "    \"Planned Economy\",\n",
    "    \"Equality: Positive\",\n",
    "    \"Opposition to Immigration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d093be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aliprandi\\Desktop\\Case_Study_TUM25\\data_preprocessing\\data_loading.py:39: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "C:\\Users\\Aliprandi\\Desktop\\Case_Study_TUM25\\data_preprocessing\\data_loading.py:54: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df_filtered = df_filtered.apply(pd.to_numeric, errors=\"ignore\")\n",
      "C:\\Users\\Aliprandi\\Desktop\\Case_Study_TUM25\\data_preprocessing\\data_loading.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_filtered['Year'] = (pd.to_datetime(df_filtered['Date'], dayfirst=True).dt.year).astype(str)\n",
      "C:\\Users\\Aliprandi\\Desktop\\Case_Study_TUM25\\data_preprocessing\\data_preprocess.py:44: UserWarning: Requested year 2021 not found in party data; falling back to most recent year '2021'.\n",
      "  warnings.warn(f\"Requested year {year!r} not found in party data; \"f\"falling back to most recent year {fallback!r}.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voters_2021.sav\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'None of the columns for policy‐dimension \"Opposition to Immigration\" were found in your voter data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m party_scaled, voter_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scaled_party_voter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOpposition to Immigration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWelfare State\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2021\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Case_Study_TUM25\\data_preprocessing\\data_preprocess.py:129\u001b[0m, in \u001b[0;36mget_scaled_party_voter_data\u001b[1;34m(x_var, y_var, year)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_scaled_party_voter_data\u001b[39m(x_var: \u001b[38;5;28mstr\u001b[39m, y_var: \u001b[38;5;28mstr\u001b[39m, year: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m--> 129\u001b[0m     party_year_filtered, voter_agg \u001b[38;5;241m=\u001b[39m \u001b[43mget_raw_party_voter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# --- Standardize all clouds ---\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     vot_pts \u001b[38;5;241m=\u001b[39m voter_agg[[x_var, y_var]]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\Desktop\\Case_Study_TUM25\\data_preprocessing\\data_preprocess.py:62\u001b[0m, in \u001b[0;36mget_raw_party_voter_data\u001b[1;34m(x_var, y_var, year, file_dir, country)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m (x_var, y_var):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered_mapping\u001b[38;5;241m.\u001b[39mget(dim):\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone of the columns for policy‐dimension \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwere found in your voter data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# --- Subset voter_df to only the surviving common items (plus your fixed ones) ---\u001b[39;00m\n\u001b[0;32m     67\u001b[0m policy_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;241m*\u001b[39mfiltered_mapping\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[1;31mKeyError\u001b[0m: 'None of the columns for policy‐dimension \"Opposition to Immigration\" were found in your voter data'"
     ]
    }
   ],
   "source": [
    "party_scaled, voter_scaled = dp.get_scaled_party_voter_data(x_var='Opposition to Immigration', y_var='Welfare State',year=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f90055",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb093da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "fig = px.scatter(\n",
    "    pd.concat([\n",
    "        voter_scaled.assign(Type=\"Voter\", Size=5, Color=\"Voter\"),\n",
    "        party_scaled.assign(Type=\"Party\", Size=15, Color=party_scaled[\"Party_Name\"])\n",
    "    ]),\n",
    "    x=\"Democracy\",\n",
    "    y=\"Welfare State\",\n",
    "    color=\"Color\",\n",
    "    symbol=\"Type\",\n",
    "    size=\"Size\",\n",
    "    title=\"Unscaled Voter and Party Positions\"\n",
    ")\n",
    "fig.update_traces(textposition=\"top center\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e681c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([voter_scaled, party_scaled], ignore_index=True)\n",
    "\n",
    "fig = px.scatter(\n",
    "    concatenated_df,\n",
    "    x='Opposition to Immigration Scaled',\n",
    "    y='Welfare State Scaled',\n",
    "    color='Label',\n",
    "    symbol='Label')\n",
    "fig.update_traces(marker=dict(size=10))\n",
    "fig.update_layout(title='Scaled Voter and Party Positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "\n",
    "x_var = \"Opposition to Immigration\"\n",
    "y_var = \"Welfare State\"\n",
    "\n",
    "x = voter_scaled[f\"{x_var} Scaled\"].values\n",
    "y = voter_scaled[f\"{y_var} Scaled\"].values\n",
    "\n",
    "data = np.vstack([x, y])\n",
    "\n",
    "kde = gaussian_kde(data, bw_method='scott')\n",
    "\n",
    "density_at_5_5 = kde([5, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voter_density(x_input, y_input):\n",
    "\n",
    "    xy = np.vstack([np.ravel(x_input), np.ravel(y_input)])\n",
    "    density_vals = kde(xy)\n",
    "    return density_vals.reshape(np.shape(x_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_density(5, 5)\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(0, 10, 100), np.linspace(0, 10, 100))\n",
    "Z = voter_density(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "X = voter_scaled[[f\"{x_var} Scaled\", f\"{y_var} Scaled\"]].values\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)\n",
    "gmm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def gmm_density(x_input, y_input):\n",
    "\n",
    "    x_flat = np.ravel(x_input)\n",
    "    y_flat = np.ravel(y_input)\n",
    "    points = np.column_stack([x_flat, y_flat])\n",
    "    \n",
    "    density_vals = np.zeros(len(points))\n",
    "    for weight, mean, cov in zip(gmm.weights_, gmm.means_, gmm.covariances_):\n",
    "        rv = multivariate_normal(mean=mean, cov=cov)\n",
    "        density_vals += weight * rv.pdf(points)\n",
    "    \n",
    "    return density_vals.reshape(np.shape(x_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgrid, Ygrid = np.meshgrid(np.linspace(0, 10, 100), np.linspace(0, 10, 100))\n",
    "Z = gmm_density(Xgrid, Ygrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weights:\", gmm.weights_)\n",
    "print(\"Means:\\n\", gmm.means_)\n",
    "print(\"Covariances:\\n\", gmm.covariances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "\n",
    "def gmm_indefinite_integral(x, y):\n",
    "    total_cdf = 0\n",
    "    point = np.array([x, y])\n",
    "    for w, mu, cov in zip(gmm.weights_, gmm.means_, gmm.covariances_):\n",
    "        total_cdf += w * multivariate_normal.cdf(point, mean=mu, cov=cov)\n",
    "    return total_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def gmm_density_and_loggrad(x_input, y_input, gmm):\n",
    "    x_flat = np.ravel(x_input)\n",
    "    y_flat = np.ravel(y_input)\n",
    "    points = np.column_stack([x_flat, y_flat])\n",
    "    N = len(points)\n",
    "\n",
    "    density_vals = np.zeros(N)\n",
    "    grad = np.zeros_like(points)\n",
    "\n",
    "    for weight, mean, cov in zip(gmm.weights_, gmm.means_, gmm.covariances_):\n",
    "        rv = multivariate_normal(mean=mean, cov=cov, allow_singular=True)\n",
    "        pdf_vals = rv.pdf(points)\n",
    "        diff = points - mean\n",
    "        inv_cov = np.linalg.pinv(cov) \n",
    "        grad_comp = -pdf_vals[:, None] * (diff @ inv_cov.T)\n",
    "\n",
    "        density_vals += weight * pdf_vals\n",
    "        grad += weight * grad_comp\n",
    "\n",
    "    eps = 1e-9\n",
    "    grad_log_density = grad / (density_vals[:, None] + eps)\n",
    "\n",
    "    return grad_log_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect(val, low, high):\n",
    "    range_size = high - low\n",
    "    val_shifted = (val - low) % (2 * range_size)\n",
    "    reflected = np.where(val_shifted < range_size, val_shifted, 2 * range_size - val_shifted)\n",
    "    return reflected + low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5941a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def run_simulation(data, T, sigma_noise, gmm_components, alpha, beta, gamma):\n",
    "\n",
    "    D, N = data.shape\n",
    "    history = [data.copy()]\n",
    "\n",
    "    for t in range(T):\n",
    "        X_t = history[-1]\n",
    "\n",
    "        X_t_noisy = X_t.T + np.random.normal(scale=1e-6, size=(N, D))\n",
    "\n",
    "        gmm = GaussianMixture(n_components=gmm_components, covariance_type='full', reg_covar=1e-2)\n",
    "        gmm.fit(X_t_noisy)\n",
    "\n",
    "        distances = cdist(X_t_noisy, X_t_noisy, metric='euclidean')\n",
    "        W = np.exp(-distances ** 2)\n",
    "        W /= W.sum(axis=1, keepdims=True)\n",
    "\n",
    "        weighted_sum = W @ X_t_noisy \n",
    "        F_x = gmm_density_and_loggrad(X_t[0, :], X_t[1, :], gmm) \n",
    "\n",
    "        noise = np.random.normal(0, sigma_noise, size=(N, D))\n",
    "\n",
    "        X_next = alpha * weighted_sum - beta * F_x + gamma * noise\n",
    "\n",
    "        X_next = np.clip(X_next, -4, 4)\n",
    "\n",
    "        for dim in range(D):\n",
    "            mask_low = X_next[:, dim] <= -4\n",
    "            X_next[mask_low, dim] = -4 + (-4 - X_next[mask_low, dim])\n",
    "            mask_high = X_next[:, dim] >= 4\n",
    "            X_next[mask_high, dim] = 4 - (X_next[mask_high, dim] - 4)\n",
    "\n",
    "        history.append(X_next.T)\n",
    "\n",
    "    final_positions = history[-1]\n",
    "    return final_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_with_simulation_separate(concatenated_df, simulation_points):\n",
    "\n",
    "    print(\"Data ranges and checks:\")\n",
    "    print(\"Opposition to Immigration Scaled min/max:\", concatenated_df['Opposition to Immigration Scaled'].min(), concatenated_df['Democracy Scaled'].max())\n",
    "    print(\"Welfare State Scaled min/max:\", concatenated_df['Welfare State Scaled'].min(), concatenated_df['Welfare State Scaled'].max())\n",
    "    \n",
    "    sim_x = np.array(simulation_points[0])\n",
    "    sim_y = np.array(simulation_points[1])\n",
    "    \n",
    "    print(\"Simulation X min/max:\", np.min(sim_x), np.max(sim_x))\n",
    "    print(\"Simulation Y min/max:\", np.min(sim_y), np.max(sim_y))\n",
    "    \n",
    "    print(\"Any NaNs or infs in simulation X?\", np.isnan(sim_x).any(), np.isinf(sim_x).any())\n",
    "    print(\"Any NaNs or infs in simulation Y?\", np.isnan(sim_y).any(), np.isinf(sim_y).any())\n",
    "    \n",
    "    def clip_data(arr, min_val=-1e3, max_val=1e3):\n",
    "        arr = np.clip(arr, min_val, max_val)\n",
    "        return arr\n",
    "    \n",
    "    sim_x = clip_data(sim_x)\n",
    "    sim_y = clip_data(sim_y)\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        concatenated_df,\n",
    "        x='Opposition to Immigration Scaled',\n",
    "        y='Welfare State Scaled',\n",
    "        color='Label',\n",
    "        symbol='Label'\n",
    "    )\n",
    "    \n",
    "    fig.add_scatter(\n",
    "        x=sim_x,\n",
    "        y=sim_y,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='rgba(0,0,0,0.2)',\n",
    "            size=4,\n",
    "            symbol='circle'\n",
    "        ),\n",
    "        name='Simulation Points'\n",
    "    )\n",
    "    \n",
    "    xmin = min(concatenated_df['Opposition to Immigration Scaled'].min(), np.min(sim_x))\n",
    "    xmax = max(concatenated_df['Opposition to Immigration Scaled'].max(), np.max(sim_x))\n",
    "    ymin = min(concatenated_df['Welfare State Scaled'].min(), np.min(sim_y))\n",
    "    ymax = max(concatenated_df['Welfare State Scaled'].max(), np.max(sim_y))\n",
    "    \n",
    "    padding_x = (xmax - xmin) * 0.1\n",
    "    padding_y = (ymax - ymin) * 0.1\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Scaled Positions with Simulation Overlay',\n",
    "        xaxis=dict(range=[xmin - padding_x, xmax + padding_x]),\n",
    "        yaxis=dict(range=[ymin - padding_y, ymax + padding_y]),\n",
    "    )\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0916f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x.__len__()             \n",
    "D = 2                \n",
    "T = 500               \n",
    "sigma_noise = 0.1\n",
    "gmm_components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1661dfb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "sim=run_simulation(data,10,sigma_noise,gmm_components,0.01,1,0.1)\n",
    "fig = plot_with_simulation_separate(concatenated_df,sim)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\"2009\", \"2013\", \"2017\", \"2021\"]\n",
    "voter_data_by_year = {}\n",
    "\n",
    "for year in years:\n",
    "    party_scaled, voter_scaled = dp.get_scaled_party_voter_data(\n",
    "        x_var='Opposition to Immigration',\n",
    "        y_var='Welfare State',\n",
    "        year=year\n",
    "    )\n",
    "\n",
    "    voter_coords = voter_scaled[['Opposition to Immigration Scaled', 'Welfare State Scaled']].to_numpy().T\n",
    "    \n",
    "    voter_data_by_year[year] = voter_coords\n",
    "\n",
    "sorted_years = sorted(voter_data_by_year.keys())\n",
    "yearly_voter_data = [voter_data_by_year[year] for year in sorted_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5fd93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def objective(params, yearly_data, T_guess, sigma_noise, gmm_components):\n",
    "    alpha, beta, gamma = params\n",
    "    total_divergence = 0.0\n",
    "\n",
    "    for i in range(len(yearly_data) - 1):\n",
    "        X_start = yearly_data[i]\n",
    "        X_real = yearly_data[i + 1]\n",
    "\n",
    "        X_sim = run_simulation(\n",
    "            data=X_start,\n",
    "            T=T_guess,\n",
    "            sigma_noise=sigma_noise,\n",
    "            gmm_components=gmm_components,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            gamma=gamma\n",
    "        )\n",
    "\n",
    "        gmm_real = GaussianMixture(n_components=gmm_components, covariance_type='full', reg_covar=1e-2).fit(X_real.T)\n",
    "        gmm_sim = GaussianMixture(n_components=gmm_components, covariance_type='full', reg_covar=1e-2).fit(X_sim.T)\n",
    "\n",
    "        log_likelihood = gmm_sim.score(X_real.T)\n",
    "\n",
    "        divergence = -log_likelihood\n",
    "        total_divergence += divergence\n",
    "\n",
    "    return total_divergence\n",
    "\n",
    "\n",
    "D, N = yearly_voter_data[0].shape\n",
    "T_guess = 50\n",
    "sigma_noise = 0.1\n",
    "gmm_components = 4\n",
    "\n",
    "initial_params = [1.0, 1.0, 0.1]\n",
    "\n",
    "result = minimize(\n",
    "    objective,\n",
    "    initial_params,\n",
    "    args=(yearly_voter_data, T_guess, sigma_noise, gmm_components),\n",
    "    method='L-BFGS-B',\n",
    "    bounds=[(0.0, 10.0), (0.0, 10.0), (0.0, 2.0)]\n",
    ")\n",
    "\n",
    "alpha_fit, beta_fit, gamma_fit = result.x\n",
    "print(\"\\n✅ Fitted Parameters:\")\n",
    "print(f\"  Alpha: {alpha_fit:.4f}\")\n",
    "print(f\"  Beta:  {beta_fit:.4f}\")\n",
    "print(f\"  Gamma: {gamma_fit:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80ee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819a909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dacb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ls_25)",
   "language": "python",
   "name": "ls_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
